{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856d8179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:23.785608Z",
     "iopub.status.busy": "2023-03-31T18:52:23.785079Z",
     "iopub.status.idle": "2023-03-31T18:52:23.790731Z",
     "shell.execute_reply": "2023-03-31T18:52:23.789769Z"
    },
    "papermill": {
     "duration": 0.024976,
     "end_time": "2023-03-31T18:52:23.794020",
     "exception": false,
     "start_time": "2023-03-31T18:52:23.769044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --upgrade -q\n",
    "#!pip uninstall nvidia_cublas_cu11 -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe13831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:36.489338Z",
     "iopub.status.busy": "2023-03-31T18:52:36.488990Z",
     "iopub.status.idle": "2023-03-31T18:52:41.176784Z",
     "shell.execute_reply": "2023-03-31T18:52:41.175669Z"
    },
    "papermill": {
     "duration": 4.700608,
     "end_time": "2023-03-31T18:52:41.179433",
     "exception": false,
     "start_time": "2023-03-31T18:52:36.478825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataframe manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# TorchVision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn_v2\n",
    "import torchvision as tv\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tracking\n",
    "import wandb\n",
    "\n",
    "# Images manipulation\n",
    "from skimage import measure\n",
    "import nibabel as nib\n",
    "import pydicom as dicom\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# System interaction\n",
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import io\n",
    "\n",
    "# Parallelization & time tests\n",
    "from multiprocessing.pool import ThreadPool, Pool\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Other\n",
    "import base64\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "NoneType = type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34aa6581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:41.200732Z",
     "iopub.status.busy": "2023-03-31T18:52:41.199987Z",
     "iopub.status.idle": "2023-03-31T18:52:41.208093Z",
     "shell.execute_reply": "2023-03-31T18:52:41.207241Z"
    },
    "papermill": {
     "duration": 0.019984,
     "end_time": "2023-03-31T18:52:41.210049",
     "exception": false,
     "start_time": "2023-03-31T18:52:41.190065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4accffa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1582891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:41.229417Z",
     "iopub.status.busy": "2023-03-31T18:52:41.228482Z",
     "iopub.status.idle": "2023-03-31T18:52:48.666717Z",
     "shell.execute_reply": "2023-03-31T18:52:48.665664Z"
    },
    "papermill": {
     "duration": 7.450976,
     "end_time": "2023-03-31T18:52:48.669770",
     "exception": false,
     "start_time": "2023-03-31T18:52:41.218794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3e1uwmkd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-shape-42</strong> at: <a href='https://wandb.ai/hitogamiag/test-logger/runs/3e1uwmkd' target=\"_blank\">https://wandb.ai/hitogamiag/test-logger/runs/3e1uwmkd</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230506_220555-3e1uwmkd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3e1uwmkd). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agavrilko/projects/research_project/mask_r_cnn/wandb/run-20230506_234250-zq5n2kcr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hitogamiag/test-logger/runs/zq5n2kcr' target=\"_blank\">feasible-disco-43</a></strong> to <a href='https://wandb.ai/hitogamiag/test-logger' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hitogamiag/test-logger' target=\"_blank\">https://wandb.ai/hitogamiag/test-logger</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hitogamiag/test-logger/runs/zq5n2kcr' target=\"_blank\">https://wandb.ai/hitogamiag/test-logger/runs/zq5n2kcr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "# Initialize new experiment\n",
    "wandb.init(\n",
    "    project = 'test-logger',#'rsna-mask-r-cnn',\n",
    "    notes = \"\"\"\n",
    "        Mask RCNN: Semantic\n",
    "        Optimizer: Adam/0.002/None/0.00001\n",
    "        Scheduler: CosineLR/0.0002\n",
    "        Backbone: RN101-FPN from DLV3 (COCO)\n",
    "        Anchors: (8,), (16,), (32,), (64,), (128,)\n",
    "        Strategy: Train all\n",
    "        Augmentation: None\n",
    "    \"\"\",\n",
    "    tags = ['baseline', 'mask-rcnn', 'kaggle'],\n",
    "#          resume = 'must',\n",
    "#          id = '1c6ogt8c',\n",
    "    save_code = True\n",
    ")\n",
    "\n",
    "# Initialize config for this experiment\n",
    "wandb.config = {\n",
    "    'batch_size' : 8,\n",
    "    'val_batch_size' : 8,\n",
    "    'num_workers' : os.cpu_count(),\n",
    "    # Only for code test. Training ratio: 0.935/0.033/0.032\n",
    "    'train_size' : 0.34,\n",
    "    'val_size' : 0.33,\n",
    "    'test_size' : 0.33,\n",
    "    'device' : 'cuda:0' if torch.cuda.is_available() else 'cpu',\n",
    "    'n_epochs' : 10generate_dataframes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d8402d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:48.701425Z",
     "iopub.status.busy": "2023-03-31T18:52:48.700923Z",
     "iopub.status.idle": "2023-03-31T18:52:49.210598Z",
     "shell.execute_reply": "2023-03-31T18:52:49.209661Z"
    },
    "papermill": {
     "duration": 0.528837,
     "end_time": "2023-03-31T18:52:49.213571",
     "exception": false,
     "start_time": "2023-03-31T18:52:48.684734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(wandb.config['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b55dd",
   "metadata": {
    "papermill": {
     "duration": 0.014616,
     "end_time": "2023-03-31T18:52:49.243705",
     "exception": false,
     "start_time": "2023-03-31T18:52:49.229089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bfa98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_uids = [uid.replace('.nii', '') for uid in os.listdir('../data/rsna-2022-cervical-spine-fracture-detection/segmentations/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3677bff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:49.273964Z",
     "iopub.status.busy": "2023-03-31T18:52:49.273621Z",
     "iopub.status.idle": "2023-03-31T18:52:49.891604Z",
     "shell.execute_reply": "2023-03-31T18:52:49.890566Z"
    },
    "papermill": {
     "duration": 0.636829,
     "end_time": "2023-03-31T18:52:49.894986",
     "exception": false,
     "start_time": "2023-03-31T18:52:49.258157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>SliceThickness</th>\n",
       "      <th>ImagePositionPatient_x</th>\n",
       "      <th>ImagePositionPatient_y</th>\n",
       "      <th>ImagePositionPatient_z</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10633</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>314.099976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10633</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>313.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10633</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>313.099976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.10633</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>312.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.10633</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>312.099976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  Slice  ImageHeight  ImageWidth  SliceThickness  \\\n",
       "0  1.2.826.0.1.3680043.10633      1          512         512             1.0   \n",
       "1  1.2.826.0.1.3680043.10633      2          512         512             1.0   \n",
       "2  1.2.826.0.1.3680043.10633      3          512         512             1.0   \n",
       "3  1.2.826.0.1.3680043.10633      4          512         512             1.0   \n",
       "4  1.2.826.0.1.3680043.10633      5          512         512             1.0   \n",
       "\n",
       "   ImagePositionPatient_x  ImagePositionPatient_y  ImagePositionPatient_z  C1  \\\n",
       "0                   -68.0                    98.0              314.099976   0   \n",
       "1                   -68.0                    98.0              313.599976   0   \n",
       "2                   -68.0                    98.0              313.099976   0   \n",
       "3                   -68.0                    98.0              312.599976   0   \n",
       "4                   -68.0                    98.0              312.099976   0   \n",
       "\n",
       "   C2  C3  C4  C5  C6  C7  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_segm = pd.read_csv('../data/rsna-2022-spine-fracture-detection-metadata/meta_segmentation_clean.csv')\n",
    "meta_segm = meta_segm[meta_segm.StudyInstanceUID.isin(available_uids)]\n",
    "meta_segm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bb46190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:49.927173Z",
     "iopub.status.busy": "2023-03-31T18:52:49.926838Z",
     "iopub.status.idle": "2023-03-31T18:52:50.474251Z",
     "shell.execute_reply": "2023-03-31T18:52:50.473157Z"
    },
    "papermill": {
     "duration": 0.565972,
     "end_time": "2023-03-31T18:52:50.477068",
     "exception": false,
     "start_time": "2023-03-31T18:52:49.911096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_segm = meta_segm[(meta_segm.iloc[:, 8:] != 0).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26a15902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:50.508275Z",
     "iopub.status.busy": "2023-03-31T18:52:50.507985Z",
     "iopub.status.idle": "2023-03-31T18:52:51.111739Z",
     "shell.execute_reply": "2023-03-31T18:52:51.110687Z"
    },
    "papermill": {
     "duration": 0.622115,
     "end_time": "2023-03-31T18:52:51.114541",
     "exception": false,
     "start_time": "2023-03-31T18:52:50.492426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PATH VARS\n",
    "\n",
    "dicom_path = Path('../data/rsna-2022-cervical-spine-fracture-detection/train_images/')\n",
    "segm_path = Path('../data/rsna-2022-cervical-spine-fracture-detection/segmentations/')\n",
    "checkpoint_path = Path('./checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec1d535c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:51.147429Z",
     "iopub.status.busy": "2023-03-31T18:52:51.147051Z",
     "iopub.status.idle": "2023-03-31T18:52:54.357415Z",
     "shell.execute_reply": "2023-03-31T18:52:54.356396Z"
    },
    "papermill": {
     "duration": 3.229887,
     "end_time": "2023-03-31T18:52:54.360475",
     "exception": false,
     "start_time": "2023-03-31T18:52:51.130588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# True means need to flip Z axis, False otherwise\n",
    "orientation_check = {}\n",
    "for uid in meta_segm.StudyInstanceUID.unique():\n",
    "    dcm1 = dicom.dcmread(dicom_path / uid / (str(10) + '.dcm'))\n",
    "    dcm2 = dicom.dcmread(dicom_path / uid / (str(20) + '.dcm'))\n",
    "    if (dcm1.ImagePositionPatient[2] - dcm2.ImagePositionPatient[2]) > 0:\n",
    "        orientation_check[uid] = True\n",
    "    else:\n",
    "        orientation_check[uid] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7346b56e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:54.392169Z",
     "iopub.status.busy": "2023-03-31T18:52:54.391801Z",
     "iopub.status.idle": "2023-03-31T18:52:56.903298Z",
     "shell.execute_reply": "2023-03-31T18:52:56.902373Z"
    },
    "papermill": {
     "duration": 2.533908,
     "end_time": "2023-03-31T18:52:56.909859",
     "exception": false,
     "start_time": "2023-03-31T18:52:54.375951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks = {}\n",
    "for uid in meta_segm.StudyInstanceUID.unique():\n",
    "    mask = nib.load(segm_path / (uid + '.nii'))\n",
    "    mask = np.asarray(mask.get_data())\n",
    "    if orientation_check[uid]:\n",
    "        mask = mask[:, :, ::-1]\n",
    "    mask = np.rot90(mask, k=1, axes=(0, 1))\n",
    "    masks[uid] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f47cbecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:56.993407Z",
     "iopub.status.busy": "2023-03-31T18:52:56.992683Z",
     "iopub.status.idle": "2023-03-31T18:52:57.556844Z",
     "shell.execute_reply": "2023-03-31T18:52:57.555561Z"
    },
    "papermill": {
     "duration": 0.617605,
     "end_time": "2023-03-31T18:52:57.565045",
     "exception": false,
     "start_time": "2023-03-31T18:52:56.947440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UIDs in train: 1\n",
      "Number of UIDs in val: 1\n",
      "Number of UIDs in test: 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split patients into train/val/test\n",
    "\"\"\"\n",
    "\n",
    "train_UIDs, test_val_UIDs = train_test_split(meta_segm.StudyInstanceUID.unique(),\n",
    "                                                   test_size=wandb.config['val_size'] + wandb.config['test_size'],\n",
    "                                                   random_state=42)\n",
    "val_UIDs, test_UIDs = train_test_split(test_val_UIDs, test_size= wandb.config['test_size'] / (wandb.config['test_size'] + wandb.config['val_size']),\n",
    "                                       random_state=42)\n",
    "\n",
    "print(f'Number of UIDs in train: {len(train_UIDs)}')\n",
    "print(f'Number of UIDs in val: {len(val_UIDs)}')\n",
    "print(f'Number of UIDs in test: {len(test_UIDs)}')\n",
    "\n",
    "train_UIDs, val_UIDs, test_UIDs = train_UIDs.tolist(), val_UIDs.tolist(), test_UIDs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb80fbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:57.597505Z",
     "iopub.status.busy": "2023-03-31T18:52:57.597031Z",
     "iopub.status.idle": "2023-03-31T18:52:58.017713Z",
     "shell.execute_reply": "2023-03-31T18:52:58.016717Z"
    },
    "papermill": {
     "duration": 0.439766,
     "end_time": "2023-03-31T18:52:58.020697",
     "exception": false,
     "start_time": "2023-03-31T18:52:57.580931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.2.826.0.1.3680043.10633']\n"
     ]
    }
   ],
   "source": [
    "print(val_UIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa2208b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:58.052219Z",
     "iopub.status.busy": "2023-03-31T18:52:58.051865Z",
     "iopub.status.idle": "2023-03-31T18:52:58.604222Z",
     "shell.execute_reply": "2023-03-31T18:52:58.602936Z"
    },
    "papermill": {
     "duration": 0.571156,
     "end_time": "2023-03-31T18:52:58.607139",
     "exception": false,
     "start_time": "2023-03-31T18:52:58.035983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wandb.save('./train_UIDs.txt')\\nwandb.save('./val_UIDs.txt')\\nwandb.save('./test_UIDs.txt')\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write train/val/test spilts\n",
    "\"\"\"\n",
    "\n",
    "def write_UIDs_in_txt(UIDs, txt_name):\n",
    "    with open(txt_name, 'w') as file:\n",
    "        file.write('\\n'.join(UIDs))\n",
    "        \n",
    "def read_UIDs_from_txt(txt_name):\n",
    "    with open(txt_name, 'r') as file:\n",
    "        return file.read().split('\\n')\n",
    "\n",
    "# When train on kaggle, must be True\n",
    "write_files = True\n",
    "if write_files:   # switch to True to rewrite train/val/test split\n",
    "    write_UIDs_in_txt(train_UIDs, 'train_UIDs.txt')\n",
    "    write_UIDs_in_txt(val_UIDs, 'val_UIDs.txt')\n",
    "    write_UIDs_in_txt(test_UIDs, 'test_UIDs.txt')\n",
    "    write_files = False\n",
    "\n",
    "train_UIDs = read_UIDs_from_txt('train_UIDs.txt')\n",
    "val_UIDs = read_UIDs_from_txt('val_UIDs.txt')\n",
    "test_UIDs = read_UIDs_from_txt('test_UIDs.txt')\n",
    "\n",
    "# Log these files\n",
    "\"\"\"wandb.save('./train_UIDs.txt')\n",
    "wandb.save('./val_UIDs.txt')\n",
    "wandb.save('./test_UIDs.txt')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96108a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:58.640651Z",
     "iopub.status.busy": "2023-03-31T18:52:58.640226Z",
     "iopub.status.idle": "2023-03-31T18:52:59.054065Z",
     "shell.execute_reply": "2023-03-31T18:52:59.053072Z"
    },
    "papermill": {
     "duration": 0.433739,
     "end_time": "2023-03-31T18:52:59.056890",
     "exception": false,
     "start_time": "2023-03-31T18:52:58.623151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataframe: (129, 15)\n",
      "Shape of val dataframe: (222, 15)\n",
      "Shape of test dataframe: (195, 15)\n"
     ]
    }
   ],
   "source": [
    "train_df = meta_segm[meta_segm.StudyInstanceUID.isin(train_UIDs)]\n",
    "val_df = meta_segm[meta_segm.StudyInstanceUID.isin(val_UIDs)]\n",
    "test_df = meta_segm[meta_segm.StudyInstanceUID.isin(test_UIDs)]\n",
    "\n",
    "print(f'Shape of train dataframe: {train_df.shape}')\n",
    "print(f'Shape of val dataframe: {val_df.shape}')\n",
    "print(f'Shape of test dataframe: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e44be7",
   "metadata": {
    "papermill": {
     "duration": 0.015055,
     "end_time": "2023-03-31T18:52:59.094683",
     "exception": false,
     "start_time": "2023-03-31T18:52:59.079628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "818f3ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:59.126915Z",
     "iopub.status.busy": "2023-03-31T18:52:59.126521Z",
     "iopub.status.idle": "2023-03-31T18:52:59.604702Z",
     "shell.execute_reply": "2023-03-31T18:52:59.603663Z"
    },
    "papermill": {
     "duration": 0.498015,
     "end_time": "2023-03-31T18:52:59.607931",
     "exception": false,
     "start_time": "2023-03-31T18:52:59.109916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom PyTorch Dataset\n",
    "\"\"\"\n",
    "\n",
    "class RSNADataset(Dataset):\n",
    "    def __init__(self, dataframe, dicom_path, segm_path, batch_size, num_workers, device, masks, transform = None) -> None:\n",
    "        super(RSNADataset, self).__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.dicom_path = dicom_path\n",
    "        self.segm_path = segm_path\n",
    "        self.masks = masks\n",
    "        \n",
    "        self.batch_index = -1\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.timer = 0\n",
    "        \n",
    "        # These variables are used to keep data of mask and save computational resources.\n",
    "        self.current_mask_UID = None\n",
    "        self.current_mask_data = None\n",
    "        \n",
    "    def load_dicom(self, path):\n",
    "        # Source: https://www.kaggle.com/code/vslaykovsky/pytorch-effnetv2-vertebrae-detection-acc-0-95\n",
    "        img=dicom.dcmread(path)\n",
    "        img.PhotometricInterpretation = 'YBR_FULL'\n",
    "        data = img.pixel_array\n",
    "        data = data - np.min(data)\n",
    "        if np.max(data) != 0:\n",
    "            data = data / np.max(data)\n",
    "        data=(data * 255).astype(np.uint8)\n",
    "        return cv.cvtColor(data, cv.COLOR_GRAY2RGB), img\n",
    "        \n",
    "    def generate_data_batch(self, ind):\n",
    "        \n",
    "        # Targets - y\n",
    "        # Targets is array of dictionaries. Each dictionary contains masks, bounding boxes and labels for 1 record of patient data\n",
    "        self.targets = []\n",
    "        \n",
    "        # Imgs - X\n",
    "        # Imgs contains DICOM images. The shape is (batch_size, 3, 512, 512)\n",
    "        self.imgs = torch.empty((0, 3, 512, 512), dtype=torch.float32)#np.array([], dtype=np.uint8).reshape(0, 3, 512, 512)\n",
    "        \n",
    "        # Get records from dataframe about what data should be loaded in the current batch\n",
    "        batches = self.dataframe.iloc[ind*self.batch_size:(ind+1)*self.batch_size, :].to_numpy()\n",
    "        \n",
    "        # Multithreading for loading data\n",
    "        \n",
    "        for batch in batches:\n",
    "            self.extract_data_from_batch(batch)\n",
    "        \n",
    "        # Convert images to tensors\n",
    "        #self.imgs = torch.as_tensor(self.imgs, dtype=torch.float32)\n",
    "        \n",
    "        if self.imgs.shape[0] == 0:\n",
    "            print('no imgs')\n",
    "            return self.__getitem__()\n",
    "        \n",
    "        # Return batch data, e.g. X and y\n",
    "        return self.imgs.to(self.device, non_blocking=True), self.targets\n",
    "    \n",
    "    def transform_function(self, img, mask):\n",
    "        transform_config = self.transform\n",
    "        \n",
    "        img, mask = TF.to_pil_image(img), TF.to_pil_image(mask.astype(np.uint8))\n",
    "        \n",
    "        if np.random.random() < transform_config['p_original']:\n",
    "            pass\n",
    "        else:\n",
    "            # Horizontal flip\n",
    "            if transform_config['p_hflip'] < np.random.random():\n",
    "                img, mask = TF.hflip(img), TF.hflip(mask)\n",
    "            \n",
    "            # Affine\n",
    "            if transform_config['p_affine'] < np.random.random():\n",
    "                affine_params = tv.transforms.RandomAffine(30).get_params((-15,15), (0.1, 0.1), (1, 1), (-15, 15), (512, 512))\n",
    "                img = TF.affine(img, *affine_params)\n",
    "                mask = TF.affine(mask, *affine_params)\n",
    "                \n",
    "            if transform_config['p_cjitter'] < np.random.random():\n",
    "                img = tv.transforms.ColorJitter(*(0.3, 0.3, 0.1, 0.1))(img)\n",
    "        \n",
    "        return np.asarray(img), np.asarray(mask)\n",
    "    \n",
    "    def extract_data_from_batch(self, batch):\n",
    "        # Define initial structure of y\n",
    "        target = {\n",
    "            'boxes':[],\n",
    "            'labels':None,\n",
    "            'masks':[]\n",
    "        }\n",
    "        \n",
    "        # Get mask from array of masks\n",
    "        mask = self.masks[batch[0]][:, :, batch[1] - 1]\n",
    "        \n",
    "        # Get vertebrae numbers then is presented on mask. C1 - 1, C2 - 2 ...\n",
    "        labels = np.unique(mask)[1:]\n",
    "        \n",
    "        labels_to_dict = []\n",
    "        \n",
    "        # if there is no vertebrae on mask\n",
    "        if len(labels) < 2:\n",
    "            return None\n",
    "        \n",
    "        # Load Dicom image\n",
    "        img = self.load_dicom(self.dicom_path / batch[0] / (str(batch[1]) + '.dcm'))[0]\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            img, mask = self.transform_function(img, mask)\n",
    "        \n",
    "        for label in labels:\n",
    "            label_mask = (mask == label).astype(np.uint8)\n",
    "            \n",
    "            # Here if we have some parts of vertebra on the mask are placed separately, they should be processed as different object (due to architecture of Mask R-CNN)\n",
    "#             segmented_mask = measure.label(label_mask)\n",
    "            \n",
    "#             for e_object in np.unique(segmented_mask)[1:]:\n",
    "#                 object_mask = (segmented_mask == e_object).astype(np.uint8)\n",
    "            \n",
    "            x, y, w, h = cv.boundingRect(label_mask)\n",
    "                \n",
    "            if sum([x, y, w, h]) == 0:\n",
    "                print('cv.boundingRect not found mask')\n",
    "                continue\n",
    "            elif w <  5 and h < 5:\n",
    "                continue\n",
    "                \n",
    "            if label.item() < 8:\n",
    "                labels_to_dict.append(label.item())\n",
    "            else:\n",
    "                labels_to_dict.append(0) # 0 is the class for other vertebraes that can be faced on the mask with C1-C7\n",
    "            target['masks'].append(label_mask)\n",
    "            target['boxes'].append(np.array([x, y, x+w, y+h]))\n",
    "                \n",
    "        # Convert to tensor\n",
    "        target['labels'] = torch.from_numpy(np.array(labels_to_dict).astype(np.int64)).to(self.device, non_blocking=True)\n",
    "        target['boxes'] = torch.from_numpy(np.array(target['boxes']).astype(np.float32)).to(self.device, non_blocking=True)\n",
    "        target['masks'] = torch.from_numpy(np.array(target['masks']).astype(np.float32)).to(self.device, non_blocking=True)\n",
    "        \n",
    "        img = tv.transforms.ToTensor()(img).unsqueeze(dim=0)\n",
    "        \n",
    "        self.imgs = torch.cat([self.imgs, img], dim=0)\n",
    "        self.targets.append(target)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(len(self.dataframe) / self.batch_size)\n",
    "    \n",
    "    # the internal counter of batches\n",
    "    def reset_batch(self):\n",
    "        self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)\n",
    "        self.batch_index = -1\n",
    "        \n",
    "    # Check are there batches or it's end of dataframe and we have to do next iteration\n",
    "    def is_end(self):\n",
    "        return False if self.batch_index < self.__len__() - 1 else True\n",
    "    \n",
    "    def __getitem__(self) -> None:\n",
    "        if self.is_end():\n",
    "            return None, None\n",
    "        \n",
    "        self.batch_index += 1\n",
    "        return self.generate_data_batch(self.batch_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49c06204",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:52:59.642802Z",
     "iopub.status.busy": "2023-03-31T18:52:59.642431Z",
     "iopub.status.idle": "2023-03-31T18:53:00.108173Z",
     "shell.execute_reply": "2023-03-31T18:53:00.107211Z"
    },
    "papermill": {
     "duration": 0.485765,
     "end_time": "2023-03-31T18:53:00.111540",
     "exception": false,
     "start_time": "2023-03-31T18:52:59.625775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop = True)\n",
    "val_df = val_df.sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "transform = {\n",
    "    'p_original' : 1,\n",
    "    'p_hflip' : 0,\n",
    "    'p_affine' : 0,\n",
    "    'p_cjitter' : 0\n",
    "}\n",
    "\n",
    "train_dataset = RSNADataset(train_df, dicom_path, segm_path, wandb.config['batch_size'], wandb.config['num_workers'], wandb.config['device'], masks, transform)\n",
    "val_dataset = RSNADataset(val_df, dicom_path, segm_path, wandb.config['val_batch_size'], wandb.config['num_workers'], wandb.config['device'], masks, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff1c55db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:00.145457Z",
     "iopub.status.busy": "2023-03-31T18:53:00.145086Z",
     "iopub.status.idle": "2023-03-31T18:53:00.619224Z",
     "shell.execute_reply": "2023-03-31T18:53:00.618207Z"
    },
    "papermill": {
     "duration": 0.494298,
     "end_time": "2023-03-31T18:53:00.622405",
     "exception": false,
     "start_time": "2023-03-31T18:53:00.128107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 15)\n",
      "(222, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee49c30",
   "metadata": {
    "papermill": {
     "duration": 0.015488,
     "end_time": "2023-03-31T18:53:00.655003",
     "exception": false,
     "start_time": "2023-03-31T18:53:00.639515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b33681c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:00.689936Z",
     "iopub.status.busy": "2023-03-31T18:53:00.689517Z",
     "iopub.status.idle": "2023-03-31T18:53:01.168928Z",
     "shell.execute_reply": "2023-03-31T18:53:01.167877Z"
    },
    "papermill": {
     "duration": 0.50109,
     "end_time": "2023-03-31T18:53:01.172219",
     "exception": false,
     "start_time": "2023-03-31T18:53:00.671129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "\n",
    "class Visualizer:\n",
    "    def __init__(self, dataframe, masks, confidence_threshold = 0.15):\n",
    "        self.dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.dataset = RSNADataset(self.dataframe, dicom_path, segm_path, 1, wandb.config['num_workers'], wandb.config['device'], masks, None)\n",
    "        self.ids_random = self.dataframe[(self.dataframe.iloc[:, 8:] != 0).any(axis=1)].sample(16).index\n",
    "        self.gt_color = [0, 255, 0, 128]\n",
    "        self.pr_color = [0, 0, 255, 128]\n",
    "    \n",
    "    def visualize(self, model):\n",
    "        i = 0\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        fig, axs = plt.subplots(4, 4, figsize = (20, 20))\n",
    "        \n",
    "        while i < 16:\n",
    "            \n",
    "            batch_index = self.ids_random[i]\n",
    "            self.dataset.batch_index = batch_index\n",
    "\n",
    "            X, y = self.dataset.__getitem__()\n",
    "            if isinstance(X, NoneType):\n",
    "                self.ids_random = self.dataframe[(self.dataframe.iloc[:, 8:] != 0).any(axis=1)].sample(1).index\n",
    "                continue\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                preds = model(X)\n",
    "\n",
    "            if len(preds) == 0:\n",
    "                continue\n",
    "\n",
    "            preds = preds[0]\n",
    "            # RGBA image with alpha channel for masks\n",
    "            rgba_img = np.zeros((X.shape[2], X.shape[3], 4))\n",
    "\n",
    "            if len(y) == 0:\n",
    "                continue\n",
    "\n",
    "            y = y[0]\n",
    "\n",
    "            ax = axs[i//4, i%4]\n",
    "\n",
    "            # Orig image\n",
    "            img = np.transpose((X.squeeze(dim = 0).cpu().numpy() * 255.0).astype(np.uint8), (1, 2, 0)).copy()\n",
    "            \n",
    "            # Scores\n",
    "            scores = preds['scores'].detach().cpu().numpy().astype(np.float32)\n",
    "            score_inds = np.where(scores > self.confidence_threshold)[0]\n",
    "            \n",
    "            # GT Bounding boxes\n",
    "            gt_bounding_boxes = y['boxes'].cpu().numpy().astype(np.int32).tolist()\n",
    "            pr_bounding_boxes = preds['boxes'].detach().cpu().numpy().astype(np.int32)[score_inds, :].tolist()\n",
    "\n",
    "            for contour in gt_bounding_boxes:\n",
    "                if len(contour) == 0:\n",
    "                    continue\n",
    "                cv.rectangle(img, (contour[0], contour[1]), (contour[2], contour[3]), self.gt_color[:3], 2)\n",
    "\n",
    "            for contour in pr_bounding_boxes:\n",
    "                if len(contour) == 0:\n",
    "                    continue\n",
    "                cv.rectangle(img, (contour[0], contour[1]), (contour[2], contour[3]), self.pr_color[:3], 2)\n",
    "\n",
    "            # Get GT Masks\n",
    "            gt_masks = y['masks'].sum(axis=0).cpu().numpy().astype(np.uint8)\n",
    "            pr_masks = preds['masks'][score_inds, :, :, :].sum(axis=0).squeeze().detach().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            # Convert numpy array of image into PIL Image object with alpha channel\n",
    "            img_pil = Image.fromarray(cv.cvtColor(img, cv.COLOR_RGB2RGBA))\n",
    "\n",
    "            # Add to image GT masks\n",
    "            gt_mask_pil = cv.cvtColor(gt_masks, cv.COLOR_GRAY2RGB)\n",
    "            pr_mask_pil = cv.cvtColor(pr_masks, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "            gt_mask_pil = np.dstack([gt_mask_pil, gt_mask_pil[:, :, 0]])\n",
    "            pr_mask_pil = np.dstack([pr_mask_pil, pr_mask_pil[:, :, 0]])\n",
    "\n",
    "            gt_mask_pil = gt_mask_pil * np.array(self.gt_color)\n",
    "            pr_mask_pil = pr_mask_pil * np.array(self.pr_color)\n",
    "\n",
    "            gt_mask_pil = Image.fromarray(gt_mask_pil.astype(np.uint8))\n",
    "            pr_mask_pil = Image.fromarray(pr_mask_pil.astype(np.uint8))\n",
    "\n",
    "            img_pil.paste(gt_mask_pil, mask = gt_mask_pil)\n",
    "            img_pil.paste(pr_mask_pil, mask = pr_mask_pil)\n",
    "\n",
    "            # Plot image\n",
    "            ax.imshow(img_pil)\n",
    "\n",
    "            # Labels\n",
    "            gt_labels = y['labels'].cpu().numpy().tolist()\n",
    "            pr_labels = preds['labels'][score_inds].detach().cpu().numpy().tolist()\n",
    "\n",
    "            #pred_labels = ...\n",
    "            ax.set_title(f'{gt_labels}|{pr_labels if len(pr_labels) < 5 else str(pr_labels)[:16] + \"...\"}')\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "        wandb.log({\"my_plot\": fig})\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faef551",
   "metadata": {
    "papermill": {
     "duration": 0.015305,
     "end_time": "2023-03-31T18:53:01.204682",
     "exception": false,
     "start_time": "2023-03-31T18:53:01.189377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fe97191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:01.238883Z",
     "iopub.status.busy": "2023-03-31T18:53:01.238449Z",
     "iopub.status.idle": "2023-03-31T18:53:01.804734Z",
     "shell.execute_reply": "2023-03-31T18:53:01.803751Z"
    },
    "papermill": {
     "duration": 0.586269,
     "end_time": "2023-03-31T18:53:01.807816",
     "exception": false,
     "start_time": "2023-03-31T18:53:01.221547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, prefix, metrics_to_log):\n",
    "        self.metrics_to_log = metrics_to_log\n",
    "        self.prefix = prefix\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.update_counter = 0\n",
    "        self.metrics = {key: 0 for key in self.metrics_to_log}\n",
    "        \n",
    "    def log(self, metrics):\n",
    "        self.update_counter += 1\n",
    "        for key in metrics.keys():\n",
    "            self.metrics[key] += metrics[key]\n",
    "            \n",
    "    def send_logs(self):\n",
    "        if self.update_counter != 0:\n",
    "            \n",
    "            self.metrics = {self.prefix + key : (value / self.update_counter) for key, value in self.metrics.items()}\n",
    "            wandb.log(self.metrics)\n",
    "            \n",
    "            self.reset()\n",
    "        \n",
    "    # Code source: https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb\n",
    "    def compute_overlaps_masks(self, masks1, masks2): #\n",
    "        \"\"\"Computes IoU overlaps between two sets of masks.\n",
    "        masks1, masks2: [Height, Width, instances]\n",
    "        \"\"\"\n",
    "\n",
    "        # If either set of masks is empty return empty result\n",
    "        if masks1.shape[-1] == 0 or masks2.shape[-1] == 0:\n",
    "            return np.zeros((masks1.shape[-1], masks2.shape[-1]))\n",
    "        # flatten masks and compute their areas\n",
    "        masks1 = np.reshape(masks1 > .5, (-1, masks1.shape[-1])).astype(np.float32)\n",
    "        masks2 = np.reshape(masks2 > .5, (-1, masks2.shape[-1])).astype(np.float32)\n",
    "        area1 = np.sum(masks1, axis=0)\n",
    "        area2 = np.sum(masks2, axis=0)\n",
    "\n",
    "        # intersections and union\n",
    "        intersections = np.dot(masks1.T, masks2)\n",
    "        union = area1[:, None] + area2[None, :] - intersections\n",
    "        overlaps = intersections / union\n",
    "\n",
    "        return overlaps\n",
    "    \n",
    "    def trim_zeros(self, x): #\n",
    "        \"\"\"It's common to have tensors larger than the available data and\n",
    "        pad with zeros. This function removes rows that are all zeros.\n",
    "\n",
    "        x: [rows, columns].\n",
    "        \"\"\"\n",
    "        assert len(x.shape) == 2\n",
    "        return x[~np.all(x == 0, axis=1)]\n",
    "    \n",
    "    def compute_matches(self, gt_boxes, gt_class_ids, gt_masks, #\n",
    "                    pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "                    iou_threshold=0.5, score_threshold=0.0):\n",
    "        \"\"\"Finds matches between prediction and ground truth instances.\n",
    "\n",
    "        Returns:\n",
    "            gt_match: 1-D array. For each GT box it has the index of the matched\n",
    "                      predicted box.\n",
    "            pred_match: 1-D array. For each predicted box, it has the index of\n",
    "                        the matched ground truth box.\n",
    "            overlaps: [pred_boxes, gt_boxes] IoU overlaps.\n",
    "        \"\"\"\n",
    "        # Trim zero padding\n",
    "        # TODO: cleaner to do zero unpadding upstream\n",
    "        gt_boxes = trim_zeros(gt_boxes)\n",
    "        gt_masks = gt_masks[..., :gt_boxes.shape[0]]\n",
    "        pred_boxes = trim_zeros(pred_boxes)\n",
    "        pred_scores = pred_scores[:pred_boxes.shape[0]]\n",
    "        # Sort predictions by score from high to low\n",
    "        indices = np.argsort(pred_scores)[::-1]\n",
    "        pred_boxes = pred_boxes[indices]\n",
    "        pred_class_ids = pred_class_ids[indices]\n",
    "        pred_scores = pred_scores[indices]\n",
    "        pred_masks = pred_masks[..., indices]\n",
    "\n",
    "        # Compute IoU overlaps [pred_masks, gt_masks]\n",
    "        overlaps = compute_overlaps_masks(pred_masks, gt_masks)\n",
    "\n",
    "        # Loop through predictions and find matching ground truth boxes\n",
    "        match_count = 0\n",
    "        pred_match = -1 * np.ones([pred_boxes.shape[0]])\n",
    "        gt_match = -1 * np.ones([gt_boxes.shape[0]])\n",
    "        for i in range(len(pred_boxes)):\n",
    "            # Find best matching ground truth box\n",
    "            # 1. Sort matches by score\n",
    "            sorted_ixs = np.argsort(overlaps[i])[::-1]\n",
    "            # 2. Remove low scores\n",
    "            low_score_idx = np.where(overlaps[i, sorted_ixs] < score_threshold)[0]\n",
    "            if low_score_idx.size > 0:\n",
    "                sorted_ixs = sorted_ixs[:low_score_idx[0]]\n",
    "            # 3. Find the match\n",
    "            for j in sorted_ixs:\n",
    "                # If ground truth box is already matched, go to next one\n",
    "                if gt_match[j] > -1:\n",
    "                    continue\n",
    "                # If we reach IoU smaller than the threshold, end the loop\n",
    "                iou = overlaps[i, j]\n",
    "                if iou < iou_threshold:\n",
    "                    break\n",
    "                # Do we have a match?\n",
    "                if pred_class_ids[i] == gt_class_ids[j]:\n",
    "                    match_count += 1\n",
    "                    gt_match[j] = i\n",
    "                    pred_match[i] = j\n",
    "                    break\n",
    "\n",
    "        return gt_match, pred_match, overlaps\n",
    "    \n",
    "    def compute_ap(self, gt_boxes, gt_class_ids, gt_masks,\n",
    "               pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "               iou_threshold=0.5):\n",
    "        \"\"\"Compute Average Precision at a set IoU threshold (default 0.5).\n",
    "\n",
    "        Returns:\n",
    "        mAP: Mean Average Precision\n",
    "        precisions: List of precisions at different class score thresholds.\n",
    "        recalls: List of recall values at different class score thresholds.\n",
    "        overlaps: [pred_boxes, gt_boxes] IoU overlaps.\n",
    "        \"\"\"\n",
    "        # Get matches and overlaps\n",
    "        gt_match, pred_match, overlaps = compute_matches(\n",
    "            gt_boxes, gt_class_ids, gt_masks,\n",
    "            pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "            iou_threshold)\n",
    "\n",
    "        # Compute precision and recall at each prediction box step\n",
    "        precisions = np.cumsum(pred_match > -1) / (np.arange(len(pred_match)) + 1)\n",
    "        recalls = np.cumsum(pred_match > -1).astype(np.float32) / len(gt_match)\n",
    "\n",
    "        # Pad with start and end values to simplify the math\n",
    "        precisions = np.concatenate([[0], precisions, [0]])\n",
    "        recalls = np.concatenate([[0], recalls, [1]])\n",
    "\n",
    "        # Ensure precision values decrease but don't increase. This way, the\n",
    "        # precision value at each recall threshold is the maximum it can be\n",
    "        # for all following recall thresholds, as specified by the VOC paper.\n",
    "        for i in range(len(precisions) - 2, -1, -1):\n",
    "            precisions[i] = np.maximum(precisions[i], precisions[i + 1])\n",
    "\n",
    "        # Compute mean AP over recall range\n",
    "        indices = np.where(recalls[:-1] != recalls[1:])[0] + 1\n",
    "        mAP = np.sum((recalls[indices] - recalls[indices - 1]) *\n",
    "                     precisions[indices])\n",
    "\n",
    "        return mAP, precisions, recalls, overlaps\n",
    "    \n",
    "    def compute_ap_range(self, gt_box, gt_class_id, gt_mask,\n",
    "                     pred_box, pred_class_id, pred_score, pred_mask,\n",
    "                     iou_thresholds=None, verbose=1):\n",
    "        \"\"\"Compute AP over a range or IoU thresholds. Default range is 0.5-0.95.\"\"\"\n",
    "        # Default is 0.5 to 0.95 with increments of 0.05\n",
    "        iou_thresholds = iou_thresholds or np.arange(0.5, 1.0, 0.05)\n",
    "\n",
    "        # Compute AP over range of IoU thresholds\n",
    "        AP = []\n",
    "        for iou_threshold in iou_thresholds:\n",
    "            ap, precisions, recalls, overlaps =\\\n",
    "                compute_ap(gt_box, gt_class_id, gt_mask,\n",
    "                            pred_box, pred_class_id, pred_score, pred_mask,\n",
    "                            iou_threshold=iou_threshold)\n",
    "            AP.append(ap)\n",
    "        mAP = np.array(AP).mean()\n",
    "        return AP, mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83550c29",
   "metadata": {
    "papermill": {
     "duration": 0.017098,
     "end_time": "2023-03-31T18:53:01.841745",
     "exception": false,
     "start_time": "2023-03-31T18:53:01.824647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88681f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:01.875150Z",
     "iopub.status.busy": "2023-03-31T18:53:01.874672Z",
     "iopub.status.idle": "2023-03-31T18:53:09.548105Z",
     "shell.execute_reply": "2023-03-31T18:53:09.547026Z"
    },
    "papermill": {
     "duration": 7.693675,
     "end_time": "2023-03-31T18:53:09.551503",
     "exception": false,
     "start_time": "2023-03-31T18:53:01.857828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth\" to /home/agavrilko/.cache/torch/hub/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlv3 = tv.models.segmentation.deeplabv3.deeplabv3_resnet101(weights = tv.models.segmentation.DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1)\n",
    "dlv3_keys = list(dlv3.get_submodule('backbone').state_dict().keys())\n",
    "\n",
    "rn101_original = tv.models.resnet.resnet101()\n",
    "del rn101_original.fc\n",
    "rn101_keys = list(rn101_original.state_dict().keys())\n",
    "\n",
    "rn101_original.load_state_dict(dlv3.get_submodule('backbone').state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54dc9f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:09.586666Z",
     "iopub.status.busy": "2023-03-31T18:53:09.586329Z",
     "iopub.status.idle": "2023-03-31T18:53:10.593499Z",
     "shell.execute_reply": "2023-03-31T18:53:10.592537Z"
    },
    "papermill": {
     "duration": 1.027756,
     "end_time": "2023-03-31T18:53:10.596665",
     "exception": false,
     "start_time": "2023-03-31T18:53:09.568909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection.backbone_utils import _resnet_fpn_extractor, _validate_trainable_layers\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "from torchvision.models.resnet import resnet101\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN, MaskRCNNHeads\n",
    "from torchvision.models.detection.faster_rcnn import _default_anchorgen, RPNHead, FastRCNNConvFCHead\n",
    "\n",
    "trainable_backbone_layers = None\n",
    "num_classes = 8\n",
    "is_trained = False\n",
    "\n",
    "trainable_backbone_layers = _validate_trainable_layers(is_trained, trainable_backbone_layers, 5, 3)\n",
    "\n",
    "# Backbone\n",
    "backbone = rn101_original\n",
    "backbone = _resnet_fpn_extractor(backbone, trainable_backbone_layers, norm_layer = nn.BatchNorm2d)\n",
    "\n",
    "# Anchor generator\n",
    "anchor_sizes = ((8,), (16,), (32,), (64,), (128,))\n",
    "aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n",
    "rpn_anchor_generator = AnchorGenerator(anchor_sizes, aspect_ratios)\n",
    "\n",
    "# RPN Module\n",
    "rpn_head = RPNHead(backbone.out_channels, rpn_anchor_generator.num_anchors_per_location()[0], conv_depth=2)\n",
    "\n",
    "# Box Module\n",
    "box_roi_pool = MultiScaleRoIAlign(featmap_names=[\"0\"], output_size=7, sampling_ratio=2)\n",
    "box_head = FastRCNNConvFCHead(\n",
    "        (backbone.out_channels, 7, 7), [256, 256, 256, 256], [1024], norm_layer=nn.BatchNorm2d\n",
    ")\n",
    "\n",
    "# Mask Module\n",
    "mask_roi_pool = MultiScaleRoIAlign(featmap_names=[\"0\", \"1\", \"2\", \"3\"], output_size=14, sampling_ratio=2)\n",
    "mask_head = MaskRCNNHeads(backbone.out_channels, [256, 256, 256, 256], 1, norm_layer=nn.BatchNorm2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17f4156c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:10.632172Z",
     "iopub.status.busy": "2023-03-31T18:53:10.631781Z",
     "iopub.status.idle": "2023-03-31T18:53:11.235834Z",
     "shell.execute_reply": "2023-03-31T18:53:11.234829Z"
    },
    "papermill": {
     "duration": 0.625677,
     "end_time": "2023-03-31T18:53:11.239020",
     "exception": false,
     "start_time": "2023-03-31T18:53:10.613343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MaskRCNN(\n",
    "    backbone,\n",
    "    num_classes=num_classes,\n",
    "    \n",
    "    # transform parameters ------------------\n",
    "    min_size=500,\n",
    "    max_size=600,\n",
    "    image_mean=None,\n",
    "    image_std=None,\n",
    "    \n",
    "    # RPN parameters -------------------------\n",
    "    rpn_anchor_generator=rpn_anchor_generator,\n",
    "    rpn_head=rpn_head,\n",
    "    rpn_pre_nms_top_n_train=500 * 4,\n",
    "    rpn_pre_nms_top_n_test=250 * 4,\n",
    "    rpn_post_nms_top_n_train=500 * 4,\n",
    "    rpn_post_nms_top_n_test=250 * 4,\n",
    "    rpn_nms_thresh=0.7,\n",
    "    rpn_fg_iou_thresh=0.7,\n",
    "    rpn_bg_iou_thresh=0.3,\n",
    "    rpn_batch_size_per_image=256,\n",
    "    rpn_positive_fraction=0.5,\n",
    "    rpn_score_thresh=0.0,\n",
    "    \n",
    "    # Box parameters ---------------\n",
    "    box_roi_pool=box_roi_pool,\n",
    "    box_head=box_head,\n",
    "    \n",
    "    # must be None when num_classes specified\n",
    "    box_predictor=None,\n",
    "    \n",
    "    box_score_thresh=0.05,\n",
    "    box_nms_thresh=0.5,\n",
    "    box_detections_per_img=100,\n",
    "    box_fg_iou_thresh=0.5,\n",
    "    box_bg_iou_thresh=0.5,\n",
    "    box_batch_size_per_image=512,\n",
    "    box_positive_fraction=0.25,\n",
    "    bbox_reg_weights=None,\n",
    "    \n",
    "    # Mask parameters --------------------------\n",
    "    mask_roi_pool=mask_roi_pool,\n",
    "    mask_head=mask_head,\n",
    "    \n",
    "    # must be None when num_classes specified\n",
    "    mask_predictor=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80ea5305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:11.273298Z",
     "iopub.status.busy": "2023-03-31T18:53:11.272960Z",
     "iopub.status.idle": "2023-03-31T18:53:16.359855Z",
     "shell.execute_reply": "2023-03-31T18:53:16.358830Z"
    },
    "papermill": {
     "duration": 5.10659,
     "end_time": "2023-03-31T18:53:16.362697",
     "exception": false,
     "start_time": "2023-03-31T18:53:11.256107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-06 23:46:31--  https://download.pytorch.org/models/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth\n",
      "Resolving download.pytorch.org (download.pytorch.org)... 13.33.243.80, 13.33.243.23, 13.33.243.91, ...\n",
      "Connecting to download.pytorch.org (download.pytorch.org)|13.33.243.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 185828065 (177M) [application/x-www-form-urlencoded]\n",
      "Saving to: maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth\n",
      "\n",
      "maskrcnn_resnet50_f 100%[===================>] 177.22M  1.96MB/s    in 92s     \n",
      "\n",
      "2023-05-06 23:48:03 (1.93 MB/s) - maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth saved [185828065/185828065]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://download.pytorch.org/models/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23a5cc76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:16.399204Z",
     "iopub.status.busy": "2023-03-31T18:53:16.398818Z",
     "iopub.status.idle": "2023-03-31T18:53:17.000291Z",
     "shell.execute_reply": "2023-03-31T18:53:16.999364Z"
    },
    "papermill": {
     "duration": 0.622602,
     "end_time": "2023-03-31T18:53:17.003039",
     "exception": false,
     "start_time": "2023-03-31T18:53:16.380437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = torch.load('maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9280cce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:17.038910Z",
     "iopub.status.busy": "2023-03-31T18:53:17.038578Z",
     "iopub.status.idle": "2023-03-31T18:53:17.490518Z",
     "shell.execute_reply": "2023-03-31T18:53:17.489577Z"
    },
    "papermill": {
     "duration": 0.472779,
     "end_time": "2023-03-31T18:53:17.493310",
     "exception": false,
     "start_time": "2023-03-31T18:53:17.020531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_keys = set(model.state_dict().keys())\n",
    "weight_keys = set(weights.keys())\n",
    "\n",
    "model_shapes = {key : value.shape for key, value in model.state_dict().items()}\n",
    "weight_shapes = {key : value.shape for key, value in weights.items()}\n",
    "\n",
    "mapping = []\n",
    "\n",
    "for key in model_keys:\n",
    "    if not (key.split('.')[0] == 'backbone' and key.split('.')[1] == 'body') and key in weight_keys and weight_shapes[key] == model_shapes[key]:\n",
    "        mapping.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ec5a32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:17.532828Z",
     "iopub.status.busy": "2023-03-31T18:53:17.532481Z",
     "iopub.status.idle": "2023-03-31T18:53:18.507973Z",
     "shell.execute_reply": "2023-03-31T18:53:18.506995Z"
    },
    "papermill": {
     "duration": 0.999891,
     "end_time": "2023-03-31T18:53:18.510892",
     "exception": false,
     "start_time": "2023-03-31T18:53:17.511001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = model.state_dict()\n",
    "for key in mapping:\n",
    "    model_dict[key] = weights[key]\n",
    "\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e611544",
   "metadata": {
    "papermill": {
     "duration": 0.046797,
     "end_time": "2023-03-31T18:53:18.600734",
     "exception": false,
     "start_time": "2023-03-31T18:53:18.553937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1364bc5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:18.679425Z",
     "iopub.status.busy": "2023-03-31T18:53:18.678941Z",
     "iopub.status.idle": "2023-03-31T18:53:20.171755Z",
     "shell.execute_reply": "2023-03-31T18:53:20.170816Z"
    },
    "papermill": {
     "duration": 1.549048,
     "end_time": "2023-03-31T18:53:20.174541",
     "exception": false,
     "start_time": "2023-03-31T18:53:18.625493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "# model_weights = api.artifact('hitogamiag/test-logger/chkp_mrcnn_10:v10')\n",
    "# model_weights.download()\n",
    "\n",
    "# model_weights = torch.load('artifacts/' + model_weights.name + '/chkp_mrcnn_10.pth')\n",
    "# model_weights = {key.replace('module.', '') : value for key, value in model_weights.items()}\n",
    "\n",
    "# model.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1b8b7",
   "metadata": {
    "papermill": {
     "duration": 0.017239,
     "end_time": "2023-03-31T18:53:20.210627",
     "exception": false,
     "start_time": "2023-03-31T18:53:20.193388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef337688",
   "metadata": {
    "papermill": {
     "duration": 0.017013,
     "end_time": "2023-03-31T18:53:20.245187",
     "exception": false,
     "start_time": "2023-03-31T18:53:20.228174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5f13f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:20.281765Z",
     "iopub.status.busy": "2023-03-31T18:53:20.281414Z",
     "iopub.status.idle": "2023-03-31T18:53:20.748963Z",
     "shell.execute_reply": "2023-03-31T18:53:20.748047Z"
    },
    "papermill": {
     "duration": 0.489369,
     "end_time": "2023-03-31T18:53:20.751821",
     "exception": false,
     "start_time": "2023-03-31T18:53:20.262452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def checkpoint(checkpoint_path, model_name):\n",
    "    if not checkpoint_path.is_dir():\n",
    "        checkpoint_path.mkdir()\n",
    "    \n",
    "    # Save trained model weights\n",
    "    save_path = checkpoint_path / (model_name + '.pth')\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    # Upload them on wandb\n",
    "    artifact = wandb.Artifact(model_name, type='checkpoint')\n",
    "    artifact.add_file(save_path)\n",
    "    wandb.log_artifact(artifact)\n",
    "    print(f'Logged {model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a1b46",
   "metadata": {
    "papermill": {
     "duration": 0.017704,
     "end_time": "2023-03-31T18:53:20.788055",
     "exception": false,
     "start_time": "2023-03-31T18:53:20.770351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fc89208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:20.826557Z",
     "iopub.status.busy": "2023-03-31T18:53:20.826197Z",
     "iopub.status.idle": "2023-03-31T18:53:21.369559Z",
     "shell.execute_reply": "2023-03-31T18:53:21.368570Z"
    },
    "papermill": {
     "duration": 0.566312,
     "end_time": "2023-03-31T18:53:21.372295",
     "exception": false,
     "start_time": "2023-03-31T18:53:20.805983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(params=model.parameters(), lr=0.0002, momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "max_num_of_iters = int(wandb.config['n_epochs'] * train_dataset.dataframe.shape[0] / wandb.config['batch_size'])\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_num_of_iters, eta_min=0)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=0.002, weight_decay=0.00001)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLAR(optimizer, step_size=3, gamma=0.1, verbose=False)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_num_of_iters, eta_min=0.0002)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "560883b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T18:53:21.410558Z",
     "iopub.status.busy": "2023-03-31T18:53:21.410174Z",
     "iopub.status.idle": "2023-03-31T23:23:52.574086Z",
     "shell.execute_reply": "2023-03-31T23:23:52.572995Z"
    },
    "papermill": {
     "duration": 16231.189378,
     "end_time": "2023-03-31T23:23:52.580056",
     "exception": false,
     "start_time": "2023-03-31T18:53:21.390678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 3.95 GiB total capacity; 3.15 GiB already allocated; 19.69 MiB free; 3.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1083255/2271681800.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# TODO: call func to get predictions and losses at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torchvision/models/detection/roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mmatched_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0mbox_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_roi_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m         \u001b[0mbox_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mclass_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_regression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, boxes, image_shapes)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscales\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_levels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         )\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m_multiscale_roi_align\u001b[0;34m(x_filtered, boxes, output_size, sampling_ratio, scales, mapper)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mspatial_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0msampling_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         )\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36mroi_align\u001b[0;34m(input, boxes, output_size, spatial_scale, sampling_ratio, aligned)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_boxes_to_roi_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     return torch.ops.torchvision.roi_align(\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/research_project/env/lib/python3.7/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 3.95 GiB total capacity; 3.15 GiB already allocated; 19.69 MiB free; 3.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer aaggregatend lr scheduler\n",
    "\n",
    "# Head - 5 epochs; resnet4+ 10 epochs; all - 15 epochs; With lr decresed by 10 every stage\n",
    "# Another is try to train only Head for 15 epochs\n",
    "model = nn.DataParallel(model).to(f'{wandb.config[\"device\"]}', non_blocking=True)\n",
    "\n",
    "send_train_logs_each_n_batches = 10\n",
    "\n",
    "# Create new loggers\n",
    "# Cannot calculate mAPs for train because of dropout layers & batchnorm\n",
    "train_logger = Evaluator(prefix='train_', metrics_to_log={\n",
    "            'loss_classifier' : 0,\n",
    "            'loss_box_reg' : 0,\n",
    "            'loss_mask' : 0,\n",
    "            'loss_objectness' : 0,\n",
    "            'loss_rpn_box_reg' : 0,\n",
    "            'total_loss' : 0\n",
    "        })\n",
    "\n",
    "val_logger = Evaluator(prefix='val_', metrics_to_log={\n",
    "            'loss_classifier' : 0,\n",
    "            'loss_box_reg' : 0,\n",
    "            'loss_mask' : 0,\n",
    "            'loss_objectness' : 0,\n",
    "            'loss_rpn_box_reg' : 0,\n",
    "            'total_loss' : 0\n",
    "        })\n",
    "\n",
    "# Visualizer\n",
    "visualizer = Visualizer(val_df, masks)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Note: we don't use dataloader because it's incorrectly working with dictionaries (and our \"y\" is list of dictionaries)\n",
    "# During the epoch, the model will be evaluated approx \"validate_n_times_per_epoch\" times\n",
    "train_send_logs_each_n_iters = 5\n",
    "\n",
    "validate_n_times_per_epoch = 5\n",
    "validate_each_n_iters = round(train_dataset.dataframe.shape[0] / train_dataset.batch_size / validate_n_times_per_epoch)\n",
    "\n",
    "# Visualize n times per epoch\n",
    "vizualize_n_times_per_epoch = 3\n",
    "vizualize_each_n_iters = round(train_dataset.dataframe.shape[0] / train_dataset.batch_size / vizualize_n_times_per_epoch)\n",
    "\n",
    "for i in range(wandb.config['n_epochs']):\n",
    "    wandb.log({'epoch' : i+1})\n",
    "    train_dataset.reset_batch()\n",
    "    while not train_dataset.is_end():\n",
    "        X, y = train_dataset.__getitem__()\n",
    "        if isinstance(X, NoneType): break;\n",
    "        \n",
    "        # TODO: call func to get predictions and losses at once\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss_dict = model(X, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses = sum(loss for loss in loss_dict.values()).sum()\n",
    "        scaler.scale(losses).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        #warmup.step()\n",
    "        # TODO: Calculate APs and mAP\n",
    "        # Log iteration results\n",
    "        train_logger.log({\n",
    "            'loss_classifier' : loss_dict['loss_classifier'].sum().item(),\n",
    "            'loss_box_reg' : loss_dict['loss_box_reg'].sum().item(),\n",
    "            'loss_mask' : loss_dict['loss_mask'].sum().item(),\n",
    "            'loss_objectness' : loss_dict['loss_objectness'].sum().item(),\n",
    "            'loss_rpn_box_reg' : loss_dict['loss_rpn_box_reg'].sum().item(),\n",
    "            'total_loss' : losses.sum().item()\n",
    "        })\n",
    "        \n",
    "        if train_logger.update_counter == train_send_logs_each_n_iters:\n",
    "            wandb.log({'lr' : optimizer.param_groups[0]['lr']})\n",
    "            train_logger.send_logs()\n",
    "        \n",
    "        # Visualize model each N iterations\n",
    "        if (train_dataset.batch_index + 1) % vizualize_each_n_iters == 0:\n",
    "            visualizer.visualize(model)\n",
    "        \n",
    "        # Validate model each N iterations\n",
    "        if (train_dataset.batch_index + 1) % validate_each_n_iters == 0:\n",
    "                \n",
    "            val_dataset.reset_batch()\n",
    "            while not val_dataset.is_end():\n",
    "                X, y = val_dataset.__getitem__()\n",
    "                if isinstance(X, NoneType): break;\n",
    "                \n",
    "                # TODO: call func to get predictions and losses at once\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    loss_dict = model(X, y)\n",
    "                \n",
    "                losses = sum(loss for loss in loss_dict.values()).sum()\n",
    "\n",
    "                # TODO: Calculate APs and mAP\n",
    "                # Log validation results\n",
    "                val_logger.log({\n",
    "                    'loss_classifier' : loss_dict['loss_classifier'].sum().item(),\n",
    "                    'loss_box_reg' : loss_dict['loss_box_reg'].sum().item(),\n",
    "                    'loss_mask' : loss_dict['loss_mask'].sum().item(),\n",
    "                    'loss_objectness' : loss_dict['loss_objectness'].sum().item(),\n",
    "                    'loss_rpn_box_reg' : loss_dict['loss_rpn_box_reg'].sum().item(),\n",
    "                    'total_loss' : losses.sum().item()\n",
    "                })\n",
    "            val_logger.send_logs()\n",
    "    \n",
    "    train_logger.send_logs()\n",
    "    visualizer.visualize(model)\n",
    "    \n",
    "    checkpoint(checkpoint_path, f'chkp_mrcnn_{i+1}')\n",
    "    \n",
    "finish_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62d18797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T23:23:52.648212Z",
     "iopub.status.busy": "2023-03-31T23:23:52.646886Z",
     "iopub.status.idle": "2023-03-31T23:24:00.828134Z",
     "shell.execute_reply": "2023-03-31T23:24:00.827238Z"
    },
    "papermill": {
     "duration": 8.224743,
     "end_time": "2023-03-31T23:24:00.830224",
     "exception": false,
     "start_time": "2023-03-31T23:23:52.605481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">feasible-disco-43</strong> at: <a href='https://wandb.ai/hitogamiag/test-logger/runs/zq5n2kcr' target=\"_blank\">https://wandb.ai/hitogamiag/test-logger/runs/zq5n2kcr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230506_234250-zq5n2kcr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee5db5",
   "metadata": {
    "papermill": {
     "duration": 0.020054,
     "end_time": "2023-03-31T23:24:00.930840",
     "exception": false,
     "start_time": "2023-03-31T23:24:00.910786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16309.000185,
   "end_time": "2023-03-31T23:24:04.302132",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-31T18:52:15.301947",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d981d6e14a4415790a1f59f2f72c1e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0fde99e482144fe5809b7f976882aef3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2e40f085de844b15a68f5e7206e8b007": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75f6e6c42678436383f3d84cac113c12",
       "placeholder": "",
       "style": "IPY_MODEL_0fde99e482144fe5809b7f976882aef3",
       "value": ""
      }
     },
     "3e6a729e31214603800916ae14844378": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f9742f78f594a67825b657e0c69291e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4049950f52704b3b90a47550c5e5e9a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50a170f6437a4c6881c45751284bc8b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8fa67ebec3c1404ca309ef6abc7e3f73",
        "IPY_MODEL_d2db0e3f727d45aa90667bdaa25829e2",
        "IPY_MODEL_72187c04d0fd4edaa8bba3a7075f6e9b"
       ],
       "layout": "IPY_MODEL_fbb2f91788ef44a78f4805ad8248ba87"
      }
     },
     "50bdd96d2d3d4a12a064ad59c807b36c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5d059273ef424b00b65b640122388ec6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d7f3609d0394518ac201cbe7a4da759": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f1fbd50b118483e8df7613932e35154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "60a6f72b0ac848569f9302f6f0890bce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2e40f085de844b15a68f5e7206e8b007",
        "IPY_MODEL_82622946a16b4421a23c46036bd9bf98"
       ],
       "layout": "IPY_MODEL_5d059273ef424b00b65b640122388ec6"
      }
     },
     "60c1c1e9688d4ca2991b2aa62444aac6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b429e1827e614264a9bcca13e110e695",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d6367d3ff68840219731aca43628c10f",
       "value": 1
      }
     },
     "6731799ca2d948d488404db15cd1161d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9a58fc3e65ab4d9d9c358978f7518d27",
       "placeholder": "",
       "style": "IPY_MODEL_50bdd96d2d3d4a12a064ad59c807b36c",
       "value": "2533.486 MB of 2533.486 MB uploaded (0.000 MB deduped)\r"
      }
     },
     "72187c04d0fd4edaa8bba3a7075f6e9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae21f71b539f4baf88efafabf23cbac5",
       "placeholder": "",
       "style": "IPY_MODEL_3f9742f78f594a67825b657e0c69291e",
       "value": " 233M/233M [00:03&lt;00:00, 73.6MB/s]"
      }
     },
     "75f6e6c42678436383f3d84cac113c12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82622946a16b4421a23c46036bd9bf98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eeedefe8cba542a883a951d0d92cdae7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5d7f3609d0394518ac201cbe7a4da759",
       "value": 0
      }
     },
     "8c24ab1632fc4546b374252d4dc6525c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8fa67ebec3c1404ca309ef6abc7e3f73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8c24ab1632fc4546b374252d4dc6525c",
       "placeholder": "",
       "style": "IPY_MODEL_5f1fbd50b118483e8df7613932e35154",
       "value": "100%"
      }
     },
     "9a58fc3e65ab4d9d9c358978f7518d27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae21f71b539f4baf88efafabf23cbac5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b429e1827e614264a9bcca13e110e695": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2db0e3f727d45aa90667bdaa25829e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e6a729e31214603800916ae14844378",
       "max": 244545539,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0d981d6e14a4415790a1f59f2f72c1e3",
       "value": 244545539
      }
     },
     "d6367d3ff68840219731aca43628c10f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eeedefe8cba542a883a951d0d92cdae7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbb2f91788ef44a78f4805ad8248ba87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc9adf20e1204e45b21d945775eaca03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6731799ca2d948d488404db15cd1161d",
        "IPY_MODEL_60c1c1e9688d4ca2991b2aa62444aac6"
       ],
       "layout": "IPY_MODEL_4049950f52704b3b90a47550c5e5e9a2"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
